{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for detecting the face in a frame\n",
    "def face_detector(img):\n",
    "    # Convert image to grayscale\n",
    "    nope = 0\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(img, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return (0,0,0,0), np.zeros((100,100), np.uint8), img\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        nope = nope+1\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "    if nope!=0:\n",
    "        f.append(nope)\n",
    "    try:\n",
    "        roi_gray = cv2.resize(roi_gray, (100,100), interpolation = cv2.INTER_AREA)\n",
    "    except:\n",
    "        return (x,w,y,h), np.zeros((100,100), np.uint8), img\n",
    "    return (x,w,y,h), roi_gray, img\n",
    "def face_detector1(img):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(img, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return (0,0,0,0), np.zeros((48,48), np.uint8), img\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "    try:\n",
    "        roi_gray = cv2.resize(roi_gray, (48,48), interpolation = cv2.INTER_AREA)\n",
    "    except:\n",
    "        return (x,w,y,h), np.zeros((48,48), np.uint8), img\n",
    "    return (x,w,y,h), roi_gray, img\n",
    "\n",
    "\n",
    "\n",
    "#getting the video feed (we can take the feed from either Ip webcam,you tube)\n",
    "def getting_video_feed(x):\n",
    "    Total_frame_with_person_count = 0\n",
    "    frame_count = 0\n",
    "    cap = cv2.VideoCapture(x)\n",
    "    while True:\n",
    "        frame_count = frame_count+1\n",
    "        ret, frame = cap.read()\n",
    "        rect, face, image = face_detector(frame)\n",
    "        rect1, face1, image1 = face_detector1(frame)\n",
    "        if np.sum([face]) != 0.0:\n",
    "            roi = face.astype(\"float\") / 255.0\n",
    "            roi = img_to_array(roi)\n",
    "            roi = np.expand_dims(roi, axis=0)\n",
    "        \n",
    "            roi1 = face1.astype(\"float\") / 255.0\n",
    "            roi1 = img_to_array(roi1)\n",
    "            roi1 = np.expand_dims(roi1, axis=0)\n",
    "            class_labels_gender = {0:\"fl\",1:\"ml\"}\n",
    "            preds_gender = classifier_gender.predict(roi)[0]\n",
    "            label_gender = class_labels_gender[preds_gender.argmax()]  \n",
    "            label_position_gender = (rect[0] + int((rect[1]/2)), rect[2] + 25)\n",
    "            cv2.putText(image, label_gender, label_position_gender , cv2.FONT_HERSHEY_SIMPLEX,2, (0,255,0), 3)\n",
    "            f.append(label_gender)\n",
    "            a.append(label_gender)\n",
    "            Total_frame_with_person_count=Total_frame_with_person_count+1\n",
    "            if label_gender == \"ml\":\n",
    "                #class_labels_male = validation_generator_male.class_indices\n",
    "                class_labels_male = {0:\"mm(1-9)\",1:\"mm(10-14)\",2:\"mm(15-18)\",3:\"mm(19-28)\",4:\"mm(28-40)\",5:\"mm(45-59)\",6:\"mm(60-x)\"}\n",
    "                preds_male = classifier_male.predict(roi)[0]\n",
    "                label_male = class_labels_male[preds_male.argmax()]\n",
    "                b.append(label_male)\n",
    "                f.append(label_male)\n",
    "            \n",
    "                #class_labels_emotion = validation_generator_emotion.class_indices\n",
    "                class_labels_emotion = {0:\"Angry\",1:\"Fear\",2:\"Happy\",3:\"Neutral\",4:\"Sad\",5:\"Surprise\"}\n",
    "                preds_emotion = classifier_emotion.predict(roi1)[0]\n",
    "                label_emotion = class_labels_emotion[preds_emotion.argmax()]\n",
    "                c.append(label_emotion)\n",
    "                f.append(label_emotion)\n",
    "            else:\n",
    "                class_labels_female = {0:\"fm(1-9)\",1:\"fm(10-14)\",2:\"fm(15-18)\",3:\"fm(19-28)\",4:\"fm(28-40)\",5:\"fm(45-59)\",6:\"fm(60-x)\"}\n",
    "                preds_female = classifier_female.predict(roi)[0]\n",
    "                label_female = class_labels_female[preds_female.argmax()]\n",
    "                b.append(label_female)\n",
    "                f.append(label_female)\n",
    "            \n",
    "                #class_labels_emotion = validation_generator_emotion.class_indices\n",
    "                class_labels_emotion = {0:\"Angry\",1:\"Fear\",2:\"Happy\",3:\"Neutral\",4:\"Sad\",5:\"Surprise\"}\n",
    "                preds_emotion = classifier_emotion.predict(roi1)[0]\n",
    "                label_emotion = class_labels_emotion[preds_emotion.argmax()]\n",
    "                c.append(label_emotion)\n",
    "                f.append(label_emotion)\n",
    "                \n",
    "                \n",
    "        cv2.imshow('All', image)\n",
    "        #we can set the frame count number whatever we find suitable\n",
    "        if frame_count>3000:\n",
    "            break\n",
    "        ch = cv2.waitKey(1)\n",
    "        if ch == 27 or ch == ord('q') or ch == ord('Q'):\n",
    "            break\n",
    "    print(\"Total_no_of_frames_captured: \",frame_count)\n",
    "    print(\"Total_no_of_frames_in_which_peoples_are_found\",Total_frame_with_person_count)\n",
    "    count_male = 0\n",
    "    count_female = 0\n",
    "    for i in a:\n",
    "        if(i == \"ml\"):\n",
    "            count_male=count_male+1\n",
    "        if(i == \"fl\"):\n",
    "            count_female=count_female+1\n",
    "            \n",
    "    count1mm=0\n",
    "    count1fm=0\n",
    "    count10mm=0\n",
    "    count10fm=0\n",
    "    count15mm=0\n",
    "    count15fm=0\n",
    "    count19mm=0\n",
    "    count19fm=0\n",
    "    count28mm=0\n",
    "    count28fm=0\n",
    "    count45mm=0\n",
    "    count45fm=0\n",
    "    count60mm=0\n",
    "    count60fm=0\n",
    "    for i in b:\n",
    "        if(i == \"mm(1-9)\"):\n",
    "            count1mm=count1mm+1\n",
    "        if(i == \"fm(1-9)\"):\n",
    "            count1fm=count1fm+1\n",
    "        if(i == \"mm(10-14)\"):\n",
    "            count10mm=count10mm+1\n",
    "        if(i == \"fm(10-14)\"):\n",
    "            count10fm=count10fm+1\n",
    "        if(i == \"mm(15-18)\"):\n",
    "            count15mm=count15mm+1\n",
    "        if(i == \"fm(15-18)\"):\n",
    "            count15fm=count15fm+1\n",
    "        if(i == \"mm(19-28)\"):\n",
    "            count19mm=count19mm+1\n",
    "        if(i == \"fm(19-28)\"):\n",
    "            count19fm=count19fm+1\n",
    "        if(i == \"mm(28-40)\"):\n",
    "            count28mm=count28mm+1\n",
    "        if(i == \"fm(28-40)\"):\n",
    "            count28fm=count28fm+1\n",
    "        if(i == \"mm(45-59)\"):\n",
    "            count45mm=count45mm+1\n",
    "        if(i == \"fm(45-59)\"):\n",
    "            count45fm=count45fm+1\n",
    "        if(i == \"mm(60-x)\"):\n",
    "            count60mm=count60mm+1\n",
    "        if(i == \"fm(60-x)\"):\n",
    "            count60fm=count60fm+1\n",
    "    count_angry = 0\n",
    "    count_fear = 0\n",
    "    count_happy = 0\n",
    "    count_neutral = 0\n",
    "    count_sad = 0\n",
    "    count_surprise = 0\n",
    "    for i in c:\n",
    "        if(i == \"Angry\"):\n",
    "            count_angry = count_angry+1\n",
    "        if(i == \"Fear\"):\n",
    "            count_fear = count_fear+1\n",
    "        if(i == \"Happy\"):\n",
    "            count_happy = count_happy+1\n",
    "        if(i == \"Sad\"):\n",
    "            count_sad = count_sad+1\n",
    "        if(i == \"Neutral\"):\n",
    "            count_neutral = count_neutral+1\n",
    "        if(i == \"Surprise\"):\n",
    "            count_surprise = count_surprise+1\n",
    "    \n",
    "    catg = {\"male count\":count_male,\"female count\":count_female}\n",
    "    for i in catg:\n",
    "        print(i,catg[i])\n",
    "    \n",
    "    catg1= {\"male (1-9) count\":count1mm,\"female (1-9) count\":count1fm,\"male (10-14) count\":count10mm,\n",
    "            \"female (10-14) count\":count10fm,\"male (15-18) count\":count15mm,\"female (15-18) count\":count15fm,\n",
    "            \"male (19-28) count\":count19mm,\"female (19-28) count\":count19fm,\"male (28-40) count\":count28mm,\n",
    "            \"female (28-40) count\":count28fm,\"male (45-59) count\":count45mm,\"female (45-59) count\":count45fm,\n",
    "            \"male (60-x) count\":count60mm,\"female (60-x) count\":count60fm}\n",
    "    \"\"\"for i in catg1:\n",
    "        print(i,catg1[i])\"\"\"\n",
    "    catg2 = {\"sad count\":count_sad,\"surprise count\":count_surprise,\"fear count\":count_fear,\"happy count\":count_happy,\n",
    "             \"angry count\":count_angry}\n",
    "    \"\"\"for i in catg2:\n",
    "        print(i,catg2[i])\"\"\"\n",
    "    print(a)\n",
    "    print(f)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import pafy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import multiprocessing\n",
    "from time import sleep\n",
    "from multiprocessing import Process\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "from keras import regularizers\n",
    "from keras.regularizers import l1\n",
    "\n",
    "\n",
    "\n",
    "a = []#for storing gender_labels\n",
    "b = []#for storing male and female ages\n",
    "c = []#for storing emotions\n",
    "e = []#for storing all the labels in a order\n",
    "f = []\n",
    "#gender predictor\n",
    "#loading the weights of gender predictor model\n",
    "classifier_gender = load_model('model.h888')\n",
    "\n",
    "#male age predictor\n",
    "#loadu=ing the weights of male_age predictor model\n",
    "classifier_male = load_model('model.h3333')\n",
    "\n",
    "#female age predictor\n",
    "#loading the weights of female_age predictor model\n",
    "classifier_female = load_model('model.h444444')\n",
    "\n",
    "#emotion predictor\n",
    "#loading the weights of emotion predictor model\n",
    "classifier_emotion = load_model('model.h55')\n",
    "\n",
    "#Taking feed from youtube\n",
    "#url = \"https://www.youtube.com/watch?v=TzMCjcVzPcM\"\n",
    "#url = \"https://www.youtube.com/watch?v=5CG-hLc1Eps\"\n",
    "#my_video = pafy.new(url)\n",
    "#play = my_video.getbest(preftype = \"mp4\")\n",
    "\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "count = 0\n",
    "while True:\n",
    "    getting_video_feed(0)\n",
    "    time.sleep(4)\n",
    "    a.clear()\n",
    "    b.clear()\n",
    "    c.clear()\n",
    "    f.clear()\n",
    "    count=count+1\n",
    "    if(count == 5):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
